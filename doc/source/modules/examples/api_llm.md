# Use ChatFAQ with an API LLM

## Overview

### Benefits of using ChatFAQ with an API LLM

- Pay as you go
- No need to deploy another component for running the LLM.
- In most cases cheaper

### Implemented LLM providers

Currently, we support the following LLM providers:

- [OpenAI GPT models](https://platform.openai.com/docs/api-reference)
- [Mistral models](https://docs.mistral.ai/)
- [Anthropic Claude models](https://docs.anthropic.com/claude/reference/getting-started-with-the-api)

## Prerequisites

- ChatFAQ installation and setup
- API key and credentials for your chosen LLM provider

## Step-by-step guide


