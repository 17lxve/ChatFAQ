import os
from logging import getLogger

from django.apps import apps
import ray

from back.apps.language_model.models.enums import (
    DeviceChoices,
    RetrieverTypeChoices,
)

from back.apps.language_model.tasks import (
    generate_titles as ray_generate_titles,
    clusterize_queries as ray_clusterize_queries,
    generate_intents as ray_generate_intents,
    get_similarity_scores as ray_get_similarity_scores,
)
from back.config.celery import app
from back.utils.ray_connection import connect_to_ray_cluster


logger = getLogger(__name__)

@app.task()
def generate_titles_task(knowledge_base_pk, n_titles=10):
    """
    Generate titles for the knowledge items of a knowledge base.
    Parameters
    ----------
    knowledge_base_pk : int
        The primary key of the knowledge base.
    n_titles : int
        The number of titles to generate for each knowledge item.
    """

    KnowledgeBase = apps.get_model("language_model", "KnowledgeBase")
    KnowledgeItem = apps.get_model("language_model", "KnowledgeItem")
    AutoGeneratedTitle = apps.get_model("language_model", "AutoGeneratedTitle")

    kb = KnowledgeBase.objects.get(pk=knowledge_base_pk)
    k_items = KnowledgeItem.objects.filter(knowledge_base=knowledge_base_pk)

    contents = [item.content for item in k_items]
    with connect_to_ray_cluster():
        # Submit the task to the Ray cluster
        logger.info("Submitting the generate_titles task to the Ray cluster...")
        task_name = f"generate_titles_{kb.name}"
        titles_ref = ray_generate_titles.options(name=task_name).remote(
            contents, n_titles, kb.get_lang().value
        )

        titles = ray.get(titles_ref)

    for item_titles, item in zip(titles, k_items):
        new_titles = [
            AutoGeneratedTitle(
                knowledge_item=item,
                title=title,
            )
            for title in item_titles
        ]
        AutoGeneratedTitle.objects.bulk_create(new_titles)

    logger.info(f"Titles generated for knowledge base: {kb.name}")


def get_similarity_scores(titles, retriever):
    """
    Get the similarity scores for a list of titles.
    Parameters
    ----------
    titles : list
        A list of titles.
    retriever :
        The retriever to use.
    Returns
    -------
    mean_similarity : float
        The mean similarity score.
    std_similarity : float
        The standard deviation of the similarity scores.
    """
    import numpy as np

    results = retriever.retrieve(titles, top_k=1)
    similarities = [item[0]["similarity"] for item in results]
    mean_similarity = np.mean(similarities)
    std_similarity = np.std(similarities)

    return mean_similarity, std_similarity


@app.task()
def generate_suggested_intents_task(knowledge_base_pk, _generate_titles=False):
    """
    Generate new intents from the users' queries.
    Parameters
    ----------
    knowledge_base_pk : int
        The primary key of the knowledge base.
    """
    if _generate_titles:
        generate_titles_task(knowledge_base_pk)

    from django.db.models import Max

    from back.apps.language_model.prompt_templates import get_queries_out_of_domain

    logger.info("generate_new_intents_task called")

    RAGConfig = apps.get_model("language_model", "RAGConfig")
    MessageKnowledgeItem = apps.get_model("language_model", "MessageKnowledgeItem")
    Message = apps.get_model("broker", "Message")
    AutoGeneratedTitle = apps.get_model("language_model", "AutoGeneratedTitle")
    Intent = apps.get_model("language_model", "Intent")

    hugginface_key = os.environ.get("HUGGINGFACE_KEY", None)

    # These are in domain titles
    titles_in_domain = AutoGeneratedTitle.objects.filter(
        knowledge_item__knowledge_base=knowledge_base_pk
    )[:100]

    # Get the RAG config that corresponds to the knowledge base
    rag_conf = RAGConfig.objects.filter(knowledge_base=knowledge_base_pk).first()
    if not rag_conf:
        logger.info(f"No RAG config found for knowledge base: {knowledge_base_pk}")
        return
    lang = rag_conf.knowledge_base.get_lang().value

    # if the retriever type is not e5, then return
    if rag_conf.retriever_config.get_retriever_type() != RetrieverTypeChoices.E5:
        logger.info(f"Intent generation is not supported for retriever type: {rag_conf.retriever_config.get_retriever_type().value} right now")
        return

    e5_model_args = {
        "model_name": rag_conf.retriever_config.model_name,
        "use_cpu": rag_conf.retriever_config.get_device() == DeviceChoices.CPU,
    }


    with connect_to_ray_cluster():

        titles_in_domain_str = [title.title for title in titles_in_domain]
        in_domain_task_ref = ray_get_similarity_scores.remote(titles_in_domain_str, rag_conf.pk, e5_model_args, rag_conf.retriever_config.batch_size)

        title_out_domain = get_queries_out_of_domain(lang)
        out_domain_task_ref = ray_get_similarity_scores.remote(title_out_domain, rag_conf.pk, e5_model_args, rag_conf.retriever_config.batch_size)

        mean_sim_in_domain, std_sim_in_domain = ray.get(in_domain_task_ref)
        mean_sim_out_domain, std_sim_out_domain = ray.get(out_domain_task_ref)

        logger.info(
            f"Mean similarity in domain: {mean_sim_in_domain}, std: {std_sim_in_domain}"
        )
        logger.info(
            f"Mean similarity out domain: {mean_sim_out_domain}, std: {std_sim_out_domain}"
        )

        # The suggested new intents will have a similarity score between the in domain queries and the out of domain queries
        new_intents_thresholds = {
            "max": mean_sim_in_domain - std_sim_in_domain,
            "min": mean_sim_out_domain + std_sim_out_domain,
        }

        logger.info(f"Suggested intents thresholds: {new_intents_thresholds}")

        # check that the max is greater than the min
        if new_intents_thresholds["max"] < new_intents_thresholds["min"]:
            logger.info(
                "Max threshold is lower than min threshold, no new intents will be generated"
            )
            return

        messages = MessageKnowledgeItem.objects.filter(
            knowledge_item__knowledge_base_id=knowledge_base_pk  # Filter by knowledge base
        ).values("message_id").annotate(
            max_similarity=Max("similarity")
        ) #

        logger.info(f"Number of messages: {messages.count()}")

        # filter the results if the max similarity is between the thresholds
        messages = messages.filter(
            max_similarity__lte=new_intents_thresholds["max"],
            max_similarity__gte=new_intents_thresholds["min"],
        )

        logger.info(f"Number of messages after filtering: {messages.count()}")

        if messages.count() == 0:
            logger.info("There are no suggested intents to generate")
            return

        messages_text = [
            Message.objects.get(id=item["message_id"]).stack[0]["payload"]
            for item in messages
        ]

    
        labels = ray.get(ray_clusterize_queries.remote(messages_text, e5_model_args, rag_conf.retriever_config.batch_size))

        k_clusters = len(set(labels)) - (1 if -1 in labels else 0)
        logger.info(f"Number of clusters: {k_clusters}")

        # list of lists of queries associated to each cluster
        clusters = [[] for _ in range(k_clusters)]
        cluster_instances = [[] for _ in range(k_clusters)]
        for label, query, message_instace in zip(labels, messages_text, messages):
            if label != -1:  # -1 is the label for outliers
                clusters[label].append(query)
                cluster_instances[label].append(message_instace)

        # generate the intents
        intents = ray.get(ray_generate_intents.remote(clusters))

        # save the intents
        new_intents = [
            Intent(
                intent_name=intent,
                auto_generated=True,
                valid=False,
                suggested_intent=True,
            )
            for intent in intents
        ]

        Intent.objects.bulk_create(new_intents)

        logger.info(f"Number of new intents: {len(new_intents)}")

        # add the messages to each intent
        for intent_cluster, intent in zip(cluster_instances, new_intents):
            # get the value of key 'message_id' from each message
            intent_cluster = [item["message_id"] for item in intent_cluster]
            intent.message.add(*intent_cluster)

        logger.info("New intents generated successfully")


@app.task()
def generate_intents_task(knowledge_base_pk, _generate_titles=False):
    """
    Generate existing intents from a knowledge base.
    Parameters
    ----------
    knowledge_base_pk : int
        The primary key of the knowledge base.
    """
    if _generate_titles:
        generate_titles_task(knowledge_base_pk)

    from back.apps.language_model.models import AutoGeneratedTitle
    KnowledgeItem = apps.get_model("language_model", "KnowledgeItem")

    Intent = apps.get_model("language_model", "Intent")
    RAGConfig = apps.get_model("language_model", "RAGConfig")
    rag_conf = RAGConfig.objects.filter(knowledge_base=knowledge_base_pk).first()
    if not rag_conf:
        logger.info(f"No RAG config found for knowledge base: {knowledge_base_pk}")
        return

    # if the retriever type is not e5, then return
    if rag_conf.retriever_config.get_retriever_type() != RetrieverTypeChoices.E5:
        logger.info(f"Intent generation is not supported for retriever type: {rag_conf.retriever_config.get_retriever_type().value} right now")
        return


    k_items = KnowledgeItem.objects.filter(knowledge_base=knowledge_base_pk)

    logger.info(f"Generating intents for {k_items.count()} knowledge items")

    # These are in domain titles
    autogen_titles = AutoGeneratedTitle.objects.filter(
        knowledge_item__knowledge_base=knowledge_base_pk
    )

    # get as maximum 10 autogen_titles per knowledge item
    final_autogen_titles = []
    for item in k_items:
        titles = autogen_titles.filter(knowledge_item=item)[:10]
        final_autogen_titles.extend(titles)

    logger.info(f"Number of titles: {len(final_autogen_titles)}")

    # get the queries
    queries = [title.title for title in final_autogen_titles]

    e5_model_args = {
        "model_name": rag_conf.retriever_config.model_name,
        "use_cpu": rag_conf.retriever_config.get_device() == DeviceChoices.CPU,
    }

    with connect_to_ray_cluster():

        # clusterize the queries
        logger.info("Clusterizing queries...")
        labels = ray.get(ray_clusterize_queries.remote(queries, e5_model_args, rag_conf.retriever_config.batch_size))
        k_clusters = len(set(labels)) - (1 if -1 in labels else 0)
        logger.info(f"Number of clusters: {k_clusters}")

        # list of lists of queries associated to each cluster
        clusters = [[] for _ in range(k_clusters)]
        cluster_instances = [[] for _ in range(k_clusters)]
        for label, query, title_instance in zip(labels, queries, final_autogen_titles):
            if label != -1:  # -1 is the label for outliers
                clusters[label].append(query)
                cluster_instances[label].append(title_instance)

        # generate the intents
        intents = ray.get(ray_generate_intents.remote(clusters))

        logger.info(f"Number of new intents: {len(intents)} generated")

        # save the intents
        new_intents = [
            Intent(
                intent_name=intent,
                auto_generated=True,
                valid=False,
                suggested_intent=False,
            )
            for intent in intents
        ]

        Intent.objects.bulk_create(new_intents)

        logger.info("Suggested intents saved successfully")

        # add the knowledge items to each intent
        for intent_cluster, intent in zip(cluster_instances, new_intents):
            # get the knowledge items from each title
            intent_cluster = [item.knowledge_item for item in intent_cluster]
            # remove duplicated knowledge items
            intent_cluster = list(set(intent_cluster))
            intent.knowledge_item.add(*intent_cluster)

        logger.info("Knowledge items added to the intents successfully")
